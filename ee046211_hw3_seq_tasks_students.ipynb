{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arrafmousa/NLP_HW3/blob/main/ee046211_hw3_seq_tasks_students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzV9wsJ5pGhf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "## HW3 - Sequential Tasks and Training Methods\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq2c8X93pGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/clouds/96/000000/keyboard.png\" style=\"height:50px;display:inline\"> Keyboard Shortcuts\n",
        "---\n",
        "* Run current cell: **Ctrl + Enter**\n",
        "* Run current cell and move to the next: **Shift + Enter**\n",
        "* Show lines in a code cell: **Esc + L**\n",
        "* View function documentation: **Shift + Tab** inside the parenthesis or `help(name_of_module)`\n",
        "* New cell below: **Esc + B**\n",
        "* Delete cell: **Esc + D, D** (two D's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZybn3NpGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/information.png\" style=\"height:50px;display:inline\"> Students Information\n",
        "---\n",
        "* Fill in\n",
        "\n",
        "|Name     |Campus Email| ID  |\n",
        "|---------|--------------------------------|----------|\n",
        "|Student 1| student_1@campus.technion.ac.il| 123456789|\n",
        "|Student 2| student_2@campus.technion.ac.il| 987654321|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDK5zqhdpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/upload-to-cloud.png\" style=\"height:50px;display:inline\"> Submission Guidelines\n",
        "---\n",
        "* Maximal garde: 100.\n",
        "* Submission only in **pairs**. \n",
        "    * Please make sure you have registered your group in Moodle (there is a group creation component on the Moodle where you need to create your group and assign members).\n",
        "* **No handwritten submissions.** You can choose whether to answer in a Markdown cell in this notebook or attach a PDF with your answers.\n",
        "* <a style='color:red'> SAVE THE NOTEBOOKS WITH THE OUTPUT, CODE CELLS THAT WERE NOT RUN WILL NOT GET ANY POINTS! </a>\n",
        "* What you have to submit:\n",
        "    * If you have answered the questions in the notebook, you should submit this file only, with the name: `ee046211_hw3_id1_id2.ipynb`.\n",
        "    * If you answered the questionss in a different file you should submit a `.zip` file with the name `ee046211_hw3_id1_id2.zip` with content:\n",
        "        * `ee046211_hw3_id1_id2.ipynb` - the code tasks\n",
        "        * `ee046211_hw3_id1_id2.pdf` - answers to questions.\n",
        "    * No other file-types (`.py`, `.docx`...) will be accepted.\n",
        "* Submission on the course website (Moodle).\n",
        "* **Latex in Colab** - in some cases, Latex equations may no be rendered. To avoid this, make sure to not use *bullets* in your answers (\"* some text here with Latex equations\" -> \"some text here with Latex equations\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSj_UufpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/online.png\" style=\"height:50px;display:inline\"> Working Online and Locally\n",
        "---\n",
        "* You can choose your working environment:\n",
        "    1. `Jupyter Notebook`, **locally** with <a href=\"https://www.anaconda.com/distribution/\">Anaconda</a> or **online** on <a href=\"https://colab.research.google.com/\">Google Colab</a>\n",
        "        * Colab also supports running code on GPU, so if you don't have one, Colab is the way to go. To enable GPU on Colab, in the menu: `Runtime`$\\rightarrow$ `Change Runtime Type` $\\rightarrow$`GPU`.\n",
        "    2. Python IDE such as <a href=\"https://www.jetbrains.com/pycharm/\">PyCharm</a> or <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>.\n",
        "        * Both allow editing and running Jupyter Notebooks.\n",
        "\n",
        "* Please refer to `Setting Up the Working Environment.pdf` on the Moodle or our GitHub (https://github.com/taldatech/ee046211-deep-learning) to help you get everything installed.\n",
        "* If you need any technical assistance, please go to our Piazza forum (`hw3` folder) and describe your problem (preferably with images)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlp1Fp4ppGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "\n",
        "* [Part 1 - Theory](#-Part-1---Theory)\n",
        "    * [Q1 - Deep NLP Case Study](#-Question-1--Deep-NLP-Case-Study)\n",
        "    * [Q2 -Layer Normalization](#-Question-2--Layer-Normalization)\n",
        "    * [Q3 - Preventing Variance Explosion](#-Question-3--Preventing-Variance-Explosion)\n",
        "    * [Q4 - Batch Normalization](#-Solution-4--Batch-Normalization)\n",
        "* [Part 2 - Code Assignments - Sequence-to-Sequence with Transformers](#-Part-2---Code-Assignments)\n",
        "    * [Task 1 - Task 1 - Loading and Observing the Data](#-Task-1----Loading-and-Observing-the-Data)\n",
        "    * [Task 2 - Preparing the Data - Separating to Inputs and Targets](#-Task-2----Preparing-the--Data---Separating-to-Inputs-and-Targets)\n",
        "    * [Task 3 - Define Hyperparameters and Initialize the Model](#-Task-3----Define-Hyperparameters-and-Initialize-the-Model)\n",
        "    * [Task 4 - Train and Evaluate the Language Model](#-Task-4----Train-and-Evaluate-the-Language-Model)\n",
        "    * [Task 5 - Generate Sentences](#-Task-5----Generate-Sentences)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtSiQX_pGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/cute-clipart/64/000000/ball-point-pen.png\" style=\"height:50px;display:inline\"> Part 1 - Theory\n",
        "---\n",
        "* You can choose whether to answser these straight in the notebook (Markdown + Latex) or use another editor (Word, LyX, Latex, Overleaf...) and submit an additional PDF file, **but no handwritten submissions**.\n",
        "* You can attach additional figures (drawings, graphs,...) in a separate PDF file, just make sure to refer to them in your answers.\n",
        "\n",
        "* $\\large\\LaTeX$ <a href=\"https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index\">Cheat-Sheet</a> (to write equations)\n",
        "    * <a href=\"http://tug.ctan.org/info/latex-refsheet/LaTeX_RefSheet.pdf\">Another Cheat-Sheet</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsqSFZG1pGhj"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 1 -Deep NLP Case Study\n",
        "---\n",
        "* You are consulting for a healthcare company. They provide you with clinical notes of the first encounter that each patient had with their doctor regarding a particular medical episode.\n",
        "* There are a total of 12 million patients and clinical notes. At the time that each clinical note was written, the underlying illnesses associated with the medical episode were unknown to the doctor. \n",
        "* The company provides you with the true set of illnesses associated with each medical episode and asks you to build a model that can infer these underlying illnesses using only the current clinical note and all previous clinical notes belonging to the patient.\n",
        "* The set of notes provided to you span 10 years; each patient therefore can have multiple clinical notes (medical episodes) in that period.\n",
        "* You also have a vector representation of each patient note (note-vector) which was built using a summation of the word vectors of the note.\n",
        "\n",
        "\n",
        "1. You assume that a patient’s past medical history is informative of their current illness. As such, you apply a recurrent neural network to predict the current illness based on the patient’s current and previous note-vectors. Explain why a recurrent neural network would yield better results than a feed-forward network in which your input is the summation of past and current note-vectors?\n",
        "**Solution:**\n",
        "\n",
        "as we know RNNs are most suitable for ML problems which cosist of sequential data, which is the case for medical history develpoment, they excel in 'memorising' current states and feeding that output back to 'new' current data and make the appropriae connections. On the other side feed-forward networks can not detect such sequentioal patterns since their architecture -as the name suggests- can infer/classify depending on the current state/input shich makes them more suitable for classification and detection purpose.\n",
        "\n",
        "2. A patient may have any number of illnesses from a list of 70,000 known medical illnesses. The output of your recurrent neural network will therefore be a vector with 70,000 elements. Each element in this output vector represents the probability that the patient has the illness that maps to that particular element. Illnesses are not mutually exclusive i.e. having one illness does not preclude you from having any other illnesses. Given this insight, is it better to have a sigmoid non-linearity or a softmax non-linearity as your output unit? Why?\n",
        "\n",
        "3. You try to figure out a better way to reduce the training and testing time of your model. You perform a run time analysis and observe that the computational bottleneck is in your output unit: the number of target illnesses is too high. Each illness in the list of 70,000 illnesses belongs to one of 300 classes (e.g. a migraine belongs to the neurological disorder class). He shares with you a dictionary which maps each illness to its corresponding class. How can you use this information to reduce the **time** complexity of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E5sZhKk_QR5"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 2 -Layer Normalization\n",
        "---\n",
        "\n",
        "1. When does Group Normalization is equivalent to Instance Normalization?\n",
        "2. When does Group Normalization is equivalent to Layer Normalization?\n",
        "3. For the following batch of $N=3$ 2D images with $C=3$ channels each, what is the output of:\n",
        "    * Batch Normalization\n",
        "    * Layer Normalization\n",
        "    * Instance Normalization\n",
        "\n",
        "\n",
        "* Use only the *mean* for the calculation, no need for the std (assume there are no learnable parameters).\n",
        "    \n",
        "$$ n=1: \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbDIwFUS_QR6"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 3 -Preventing Variance Explosion\n",
        "---\n",
        "This question relates to lectures 8-9 (from slide 7):\n",
        "\n",
        "Find an initializtion scheme such that $$ \\forall l, i,: \\text{(1) } \\mathbb{E}\\left[F_l(u_l)|u_l\\right]=0, \\text{ (2) } Var(u_l[i]) = 1, $$ assuming skip connections: $u_{l+1} = u_l + F_l(u_l)$ with a single skip $F_l(u_l)=W_l\\phi(u_l)+b_l$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1L6nZyy_QR6"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 4 -Batch Normalization\n",
        "---\n",
        "This question relates to lectures 8-9 (from slide 9):\n",
        "\n",
        "Prove that **without** regularization, BatchNorm **scale invariance** for parameters $\\mathbf{w}$ implies:\n",
        "1. $\\nabla \\mathcal{L}(\\mathbf{w})^T\\mathbf{w} = 0$\n",
        "2. And under gradient flow dynamics ($\\dot{\\mathbf{w}} = -\\eta \\nabla \\mathcal{L}(\\mathbf{w})$) this implies (L2) norm conservation: $\\forall t: ||\\mathbf{w}(t)||^2 = C$\n",
        "\n",
        "Hint: see results from the multilayer networks lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-14iM7pGhm"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/officel/80/000000/code.png\" style=\"height:50px;display:inline\"> Part 2 - Code Assignments\n",
        "---\n",
        "* You must write your code in this notebook and save it with the output of all of the code cells.\n",
        "* Additional text can be added in Markdown cells.\n",
        "* You can use any other IDE you like (PyCharm, VSCode...) to write/debug your code, but for the submission you must copy it to this notebook, run the code and save the notebook with the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiWKEwmt_QR6",
        "outputId": "26125959-eb05-4c99-defd-96bcc524ff08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 8.3 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata) (2.23.0)\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.1 MB/s eta 0:00:47tcmalloc: large alloc 1147494400 bytes == 0x65d56000 @  0x7f6df7df2615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n",
            "\u001b[K     |████████████████████████████████| 887.4 MB 1.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchdata) (4.4.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 86.6 MB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 31 kB/s \n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 11 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchdata) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchdata) (57.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Installing collected packages: nvidia-cublas-cu11, urllib3, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.6.0 torch-1.13.1 torchdata-0.5.1 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "# this part uses the Wikitext-2 dataset. To access torchtext datasets, please install `torchdata`:\n",
        "# `pip install torchdata` ir `conda install -c pytorch torchdata` in activated environment \n",
        "# or `!pip install torchdata` on colab.\n",
        "!pip install torchdata\n",
        "# notes:\n",
        "# torch=1.13.0 <-> torchtext 0.14.0\n",
        "# torch=1.12.1 <-> torchtext 0.13.1\n",
        "# !pip install torchtext==0.13.1 --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N62c_rE_QR7",
        "outputId": "3bdbd7d2-6c9e-4345-ac13-92fab3f46436"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe7c59991d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# imports for the practice (you can add more if you need)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "from typing import Tuple\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "# torchtext\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "seed = 211\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beEoHXLX_QR7",
        "outputId": "78006f89-e7ce-4b29-91b6-410bb3b9dbf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch: 1.13.1+cu117, torchtext: 0.14.0\n"
          ]
        }
      ],
      "source": [
        "print(f'pytorch: {torch.__version__}, torchtext: {torchtext.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJbCncz7_QR7"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/bubbles/50/000000/workflow.png\" style=\"height:50px;display:inline\">  Sequence-to-Sequence with Transformers\n",
        "---\n",
        "* In this exercise, you are going to build a language model using PyTroch's Transformer module.\n",
        "* We will work with the **Wikitext-2** dataset: the WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia.\n",
        "* After training, you will be able to generate senetences!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEIxsfE-_QR7"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 1  - Loading and Observing the Data\n",
        "---\n",
        "1. Run the following cells that define the functions `batchify` and `data_process` and initialize the tokenizer, vocabulary and the WikiText2 train dataset.\n",
        "2. Create the train, valid and test data using the provided `batchify` function.\n",
        "5. Print the shape of `train_data`, write in a comment the meaning of each dimension (e.g. `# [meaning of dim1, meaning of dim2]`).\n",
        "6. Print the first 20 words of one training sample from `train_data`. Use the vocabulary you built to transfer between tokens to words: `itos = vocab.vocab.get_itos()` will give a \"int to string\" list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6q0G-TV_QR7"
      },
      "outputs": [],
      "source": [
        "def batchify(data, bsz):\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIRepkD7_QR7"
      },
      "outputs": [],
      "source": [
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfinnLfR_QR7"
      },
      "outputs": [],
      "source": [
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91sqcM2C_QR7"
      },
      "outputs": [],
      "source": [
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LCl-uN8_QR8"
      },
      "outputs": [],
      "source": [
        "batch_size = 20\n",
        "eval_batch_size = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaZlb8lz_QR8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "train_data = batchify(train_data, batch_size)\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H0h2q_k_QR8"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 2  - Preparing the  Data - Separating to Inputs and Targets\n",
        "---\n",
        "* For a language modeling task, the model needs the following words as `Target`.\n",
        "    * For example, for the senetence \"I have a nice dog\", the model will be given \"I have a nice\" as input, and \"have a nice dog\" as the target.\n",
        "* Implement (complete) the function `get_batch(source, i, bptt)`: it generates the input and target sequence for the transformer model. It subdivides the source data into chunks of length `bptt`.\n",
        "    * For example, for `bptt=2` and at `i=0`, the output of `data, target = get_batch(train_data, i=0, bptt=2)`: `data` will be of shape (2, 20), where the batch size is 20 and `target` will be of length 40 (the target for each element is two words, but we flatten `target`).\n",
        "    * Example: for `bptt=2`, and the ABCDEFG... characters as input, our batches will be in the form of: `data=[a, b], target=[b, c]`. For `bptt=3`: `data=[a, b, c], target=[b, c, d]` and so on. This one example is a batch.\n",
        "    * Print a sample from `data` and `target`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me_NrwWV_QR8",
        "outputId": "dff1a133-da6f-4b05-df7e-7a26caba0ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('DEF', '')\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "def get_batch(source, i, bptt):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: int\n",
        "        bptt: int\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i + seq_len]\n",
        "    tgt_offset = min(len(data)-bptt,bptt)\n",
        "    target = data[tgt_offset-1:tgt_offset+bptt-1]\n",
        "    return data, target\n",
        "\n",
        "mine = \"ABCDEFGHIJKLMNOP\"\n",
        "print(get_batch(mine,3,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDWc-1NN_QR8"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 3  - Define Hyperparameters and Initialize the Model\n",
        "---\n",
        "* Define the following hyperparameters (`[a, b]` means in the range between `a` and `b`):\n",
        "    * Embedding size: choose from `[200, 250]`\n",
        "    * Number of hidden units: choose from `[200, 250]`\n",
        "    * Number of layers: choose from `[2, 4]`\n",
        "    * Number of attention heads: choose from `[2, 4]`\n",
        "    * Dropout: choose from `[0.0, 0.3]`\n",
        "    * Loss criterion: `nn.CrossEntropyLoss()`\n",
        "    * Optimizer: choose from `[SGD, Adam, RAdam]`\n",
        "    * Learning rate: choose from `[5e-3, 5.0]`\n",
        "    * Learning Scheduler: `torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)` or any scheduler of your choosing.\n",
        "    * Transformer LayerNormalization: `post` (`norm_first=False`) or `pre` (`norm_first=True`).\n",
        "* Intialize an instance of `TransformerModel` (given) and send it to `device`. Note that you need to give it the number of tokens to define the output of the decoder. You should use the number of tokens in the vocabulary. Print the number of tokens,  print **all** the chosen hyper-parameters and print the model (`print(model`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdoFZm5g_QR8"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "    \n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5, norm_first=False):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout, norm_first=norm_first)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS3KRZNo_QR8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPL51TVI_QR8"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 4  - Train and Evaluate the Language Model\n",
        "---\n",
        "* Fill in the missing line in the training code and train the model.\n",
        "* Use `bptt=35`.\n",
        "* Use the provided function to evaluate it on the validatation set (after each epoch) and on test test (after training is done). **Print and plot** the results (loss and perplexity).\n",
        "* If you see that the performance does not improve, go back to Task 3 and re-think you hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDfVQF9i_QR9"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, eval_data):\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i, bptt)\n",
        "            seq_len = data.size(0)\n",
        "            if seq_len != bptt:\n",
        "                src_mask = src_mask[:seq_len, :seq_len]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z6krWqh_QR9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "def train(model, bptt):\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i, bptt)\n",
        "        seq_len = data.size(0)\n",
        "        if seq_len != bptt:  # only on last batch\n",
        "            src_mask = src_mask[:seq_len, :seq_len]\n",
        "        output = # complete\n",
        "        loss = # complete\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heEeV6hC_QR9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs = # complete the number of epochs to run\n",
        "best_model = None\n",
        "bptt = 35\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    # complete: call train() here with appropriate paramteters\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42WqXbvt_QR9"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 5  - Generate Sentences\n",
        "---\n",
        "Use the following function to generate 3 sentences of length 20, and print them. Do they make sense? (you can compare generated sentences over epochs, to see if some logic is gained during training)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzwKsODy_QR9"
      },
      "outputs": [],
      "source": [
        "def generate(model, vocab, nwords=100, temp=1.0):\n",
        "    model.eval()\n",
        "    ntokens = len(vocab)\n",
        "    itos = vocab.vocab.get_itos()\n",
        "    model_input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "    words = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(nwords):\n",
        "            output = model(model_input, None)\n",
        "            word_weights = output[-1].squeeze().div(temp).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
        "            model_input = torch.cat([model_input, word_tensor], 0)\n",
        "            word = itos[word_idx]\n",
        "            words.append(word)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbtPSC-M_QR9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Yout code Here\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtpwCln9_QR9"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}